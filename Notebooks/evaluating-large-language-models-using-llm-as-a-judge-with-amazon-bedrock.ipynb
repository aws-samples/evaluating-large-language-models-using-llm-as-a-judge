{
    "cells": [
     {
      "cell_type": "markdown",
      "id": "3c825696-de59-4e70-8461-af86a02d812b",
      "metadata": {
       "tags": []
      },
      "source": [
       "# Evaluating Large Language Models using LLM-as-a-Judge with Amazon Bedrock"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "90832ab8-1405-4c45-b185-e65cf8b3b13e",
      "metadata": {},
      "source": [
       "This notebook serves as a base for evaluating Large Language Models using LLM-as-a-Judge with Amazon Bedrock. \n",
       "\n",
       ">  This notebook should work well with the Data Science 3.0 kernel in SageMaker Studio\n",
       "\n",
       "\n",
       "Evaluating large language models (LLM) is challenging due to their broad capabilities and the inadequacy of existing benchmarks in measuring human preferences. To address this, strong LLMs are used as judges to evaluate these models on more open-ended questions. The agreement between LLM judges and human preferences has been verified by introducing two benchmarks: [Multi Turn (MT)-bench](https://github.com/lm-sys/FastChat/tree/main/fastchat/llm_judge/data/mt_bench), a multi-turn question set, and [Chatbot Arena](https://arena.lmsys.org/), a crowdsourced battle platform. The results reveal that strong LLM judges can match both controlled and crowdsourced human preferences well, achieving over 80% agreement, the same level of agreement between humans. This makes LLM-as-a-judge a scalable and explainable way to approximate human preferences, which are otherwise very expensive to obtain.\n",
       "\n",
       "> ℹ️  **Note:** The evaluation steps in this lab are based on the paper  [Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena](https://arxiv.org/pdf/2306.05685.pdf).\n",
       "\n",
       "This lab addresses this challenge by providing a practical solution for evaluating LLMs using LLM-as-a-Judge with Amazon Bedrock.  This is relevant for developers and researchers working on evaluating LLM based applications. In the notebook you are guided using MT-Bench questions to generate test answers and evaluate them with a single-answer grading using the Bedrock API, Python and Langchain. For demonstration purpose of this lab Claude Instant is evaluated and Claude 3 Sonnet is used as strong LLM judge. The notebook consists of the following chapters: \n",
       "\n",
       "1) [Setup of the environment](#1.-Setup-of-the-enviroment)\n",
       "2) [Load MT-Bench questions](#2.-Load-MT-Bench-questions)\n",
       "3) [Generate test answers from LLM which should be evaluated](#3.-Generate-test-answers-from-LLM-which-should-be-evaluated)\n",
       "4) [Evaluate answers with strong LLM-as-a-judge](#4.-Evaluate-answers-with-strong-LLM-as-a-judge)\n",
       "5) [Generate explanation for average rating score](#5.-Generate-explanation-for-average-rating-score)"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "8c45dfee-35e1-467e-b831-f3b72f97f017",
      "metadata": {},
      "source": [
       "## 1. Setup of the enviroment"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "cd06d4c4-500f-4dd0-ba19-6559f85fde9b",
      "metadata": {},
      "source": [
       "We start by installing the required libraries."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 2,
      "id": "bb52e396-d5b3-4a6c-bc85-5a577efd33cf",
      "metadata": {},
      "outputs": [],
      "source": [
       "%%capture \n",
       "%pip install langchain==0.1.10 boto3 tqdm"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "6f81966d-ec79-42f1-9d05-446b5814b42f",
      "metadata": {},
      "source": [
       "## 2. Load MT-Bench question set"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "eb150ca6-5373-48d9-8472-2266c1468e30",
      "metadata": {},
      "source": [
       "This lab uses the MT-Bench questions set which consists of 80 high-quality multi-turn questions. They are designed to test multi-turn conversation and instruction-following ability, covering common use cases and focusing on challenging questions to differentiate models.\n",
       "\n",
       "To evaluate custom applications or fine tuned LLMs, questions should be adjusted or created according to the use cases. They should focus on covering common uses cases and usage patterns.\n",
       "\n",
       "We download the questions to use them for evaluation."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c19cfdf0-b995-4898-9d93-032c714bd645",
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "# Import necessary libraries\n",
       "import requests\n",
       "import json\n",
       "\n",
       "# Download MT-Bench questions\n",
       "url = \"https://raw.githubusercontent.com/lm-sys/FastChat/main/fastchat/llm_judge/data/mt_bench/question.jsonl\"\n",
       "response = requests.get(url)\n",
       "lines = response.text.split(\"\\n\") \n",
       "\n",
       "# Iterate through lines and append them to questions array as json\n",
       "questions = []\n",
       "for line in lines:\n",
       "  if line:\n",
       "    questions.append(json.loads(line))"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "4133b71d-9ee9-4808-85f3-f096f5e7e0fe",
      "metadata": {},
      "source": [
       "## 3. Generate test answers from LLM which should be evaluated"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "ded3bed1-f6b7-4775-9f8b-6bbee2b962eb",
      "metadata": {},
      "source": [
       "Now that we have the questions stored, we use the LLM which should be evaluated to generate the answers to these questions. First we create a prompt template which we use in a second step to generate each answer."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d8896ed0-4d83-4774-bb9f-bd4d6b5fb088",
      "metadata": {},
      "outputs": [],
      "source": [
       "# Import necessary libraries\n",
       "from langchain.prompts import PromptTemplate\n",
       "from langchain_community.chat_models import BedrockChat\n",
       "import boto3\n",
       "\n",
       "# Create bedrock client\n",
       "boto3_bedrock = boto3.client('bedrock-runtime', region_name='us-east-1')"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3ff03e7e-31c2-4090-a3f1-b2bd013138a0",
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "# Create a prompt template to generate a question a end-user could have about each open ended question\n",
       "initial_question_prompt_template = PromptTemplate(\n",
       "    input_variables=[\"input\",\"history\"],\n",
       "    template=\"\"\"HUMAN:\n",
       "    <role>You are an artificial intelligence assistant and answer questions from a curious user</role>\n",
       "    <task> Give a helpful, detailed, and polite answers to the user's question</task> \n",
       "    \n",
       "    Current conversation:\n",
       "    <conversation_history>\n",
       "    {history}\n",
       "    </conversation_history>\n",
       "    \n",
       "    Here is the human's next reply:\n",
       "    <human_reply>\n",
       "    {input}\n",
       "    </human_reply>\n",
       "\n",
       "    ANSWER:\"\"\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e20f225d-8821-4524-bf35-791ebf07caff",
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "# For each model provider there are different parameters to define when inferencing against the model. These depend on the use case.\n",
       "inference_modifier = {\n",
       "                        \"temperature\": 0.5,\n",
       "                        \"top_k\": 250,\n",
       "                        \"top_p\": 1,\n",
       "                    }\n",
       "                     \n",
       "\n",
       "evaluate_llm = BedrockChat(model_id = \"anthropic.claude-instant-v1\",\n",
       "                    client = boto3_bedrock, \n",
       "                    model_kwargs = inference_modifier \n",
       "                    )"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 7,
      "id": "92bc75f6-8dcb-488b-954a-c8bd1611e1da",
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "# Import necessary libraries\n",
       "from langchain.memory import ConversationBufferMemory\n",
       "from langchain.chains import ConversationChain\n",
       "from tqdm.auto import tqdm"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "7f67a224-e317-42d6-82a4-9af60b033210",
      "metadata": {},
      "source": [
       "ℹ️  **Note:** The next steps takes several minutes to complete."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d81da9c9-dddd-43e7-a268-d7d4d26ed49a",
      "metadata": {
       "tags": []
      },
      "outputs": [
       {
        "data": {
         "application/vnd.jupyter.widget-view+json": {
          "model_id": "86dfc4c88a7e4c289ae35ca1377a03bf",
          "version_major": 2,
          "version_minor": 0
         },
         "text/plain": [
          "  0%|          | 0/80 [00:00<?, ?it/s]"
         ]
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ],
      "source": [
       "# Create evaluation answers\n",
       "for question in tqdm(questions):\n",
       "    memory = ConversationBufferMemory(memory_key=\"history\", return_messages=True, ai_prefix=\"A\", human_prefix=\"H\")\n",
       "    conversation = ConversationChain(llm=evaluate_llm, verbose=False, memory=memory)\n",
       "    conversation.prompt = initial_question_prompt_template\n",
       "    question['answers'] = []\n",
       "    for turn in question['turns']:\n",
       "        question['answers'].append(conversation.invoke(input=turn))"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "f9e68c6b-c0be-4416-9ba9-e47c2c1ecd61",
      "metadata": {},
      "source": [
       "## 4. Evaluate answers with strong LLM-as-a-Judge"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "a99b7756-952d-479e-8e4d-f4733a924a3a",
      "metadata": {},
      "source": [
       "In this step we use the strong LLM-as-a-Judge for evaluation.\n",
       "\n",
       "Keep mind there are certian biases and limitations to this approach:\n",
       "- Position bias refers to the tendency of LLMs used as judges, to be influenced by the position or order of information presented to them.\n",
       "- Verbosity bias refers to the tendency of LLMs used as judges, to prefer verbose or overly long responses, even when a more concise answer would be more appropriate.\n",
       "- Self-enhancement bias refers to the tendency of LLMs used as judges, to evaluate or present themselves in a more favorable light, even if it may not align with reality.\n",
       "\n",
       "These limitations have to be taken into consideration when creating custom questions, creating the prompt templates, and choosing a LLM-as-a-Judge.\n",
       "However, despite these limitations the agreement between LLM judges and humans is high.\n",
       "\n",
       "First we create a prompt template the generate a ranking score from 0..10 and an explanation. In the second step, we calculate the average ranking score, display the distribution of ranking scores, and an overall explanation of the average score.\n"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 9,
      "id": "45a52d85-ddf4-41ee-9822-3853ff8a8413",
      "metadata": {},
      "outputs": [],
      "source": [
       "# Create a prompt template to generate a ranking and an explanation.\n",
       "eval_prompt_template = PromptTemplate(\n",
       "    input_variables=[\"question1\",\"answer1\",\"question2\",\"answer2\"],\n",
       "    template=\"\"\"HUMAN:\n",
       "    <role>Please act as an impartial judge and evaluate the quality of the response provided by an AI assistant to the user question displayed below.</role>\n",
       "    <task>Your evaluation should consider factors such as the helpfulness, relevance, accuracy, depth, creativity, and level of detail of the response. Your evaluation should focus on the assistant's answer to the second user question. Begin your evaluation by providing a short explanation. Be as objective as possible. After providing your explanation, you must rate the response on a scale of 1 to 10 by strictly following this format: \\\"<rating></rating>\\\", for example: \\\"Rating: <rating>5</rating>\\</task> \n",
       "    \n",
       "    <user_assistant_conversation>\n",
       "        Human:\n",
       "        <question_1>\n",
       "        {question1}\n",
       "        </question_1>\n",
       "\n",
       "        Assistant:\n",
       "        <answer_1>\n",
       "        {answer1}\n",
       "        </answer_1>\n",
       "\n",
       "        Human:\n",
       "        <question_2>\n",
       "        {question2}\n",
       "        </question_2>\n",
       "\n",
       "        Assistant:\n",
       "        <answer_2>\n",
       "        {answer2}\n",
       "        </answer_2>\n",
       "    </user_assistant_conversation>\n",
       "\n",
       "    ANSWER:\"\"\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 10,
      "id": "63d18812-ed8b-48b2-a520-448b74a99e03",
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "# For each model provider there are different parameters to define when inferencing against the model. These depend on the use case.\n",
       "eval_inference_modifier = {\n",
       "                        \"temperature\": 0.5,\n",
       "                        \"top_k\": 250,\n",
       "                        \"top_p\": 1,\n",
       "                    }\n",
       "                     \n",
       "\n",
       "eval_llm = BedrockChat(model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
       "                    client = boto3_bedrock, \n",
       "                    model_kwargs = inference_modifier \n",
       "                    )"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "e0e0ac00-172c-4760-93ca-9b8de10345bd",
      "metadata": {},
      "source": [
       "ℹ️  **Note:** The next steps takes several minutes to complete."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 11,
      "id": "90722ec0-9a6c-4345-a4f4-1c41cb029afb",
      "metadata": {
       "tags": []
      },
      "outputs": [
       {
        "data": {
         "application/vnd.jupyter.widget-view+json": {
          "model_id": "7b44f895bfcd4623a52d933260af4053",
          "version_major": 2,
          "version_minor": 0
         },
         "text/plain": [
          "  0%|          | 0/80 [00:00<?, ?it/s]"
         ]
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ],
      "source": [
       "# Evaluate previous generated answers\n",
       "import re\n",
       "amount_questions = 0\n",
       "ratings_add_up = 0\n",
       "reg_str = \"<rating>(.*?)</rating>\"\n",
       "explanation_rating = []\n",
       "for question in tqdm(questions):\n",
       "    question1 = question['answers'][0]['input']\n",
       "    question2 = question['answers'][1]['input']\n",
       "    answer1 = question['answers'][0]['response']\n",
       "    answer2 = question['answers'][1]['response']\n",
       "    question['rating_text'] = eval_llm.invoke(eval_prompt_template.format(question1 = question1, answer1 = answer1, question2=question2, answer2=answer2)).content\n",
       "    tag_value = re.search(reg_str, question['rating_text'])\n",
       "    if tag_value: \n",
       "        question['rating_score'] = tag_value.group(1)\n",
       "        explanation_rating.append(question['rating_text'])\n",
       "        amount_questions = amount_questions + 1\n",
       "        ratings_add_up = ratings_add_up + int(question['rating_score'])"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 12,
      "id": "ad0bf06d-dd94-4cdc-9855-41a596328302",
      "metadata": {
       "tags": []
      },
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "The average rating score is: 8.6125\n"
        ]
       }
      ],
      "source": [
       "# Calculate the average rating score\n",
       "average_rating = ratings_add_up/amount_questions\n",
       "print(\"The average rating score is: {}\".format(average_rating))"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 13,
      "id": "7917b47a-4c7c-4ec2-94fb-f290a1d2addb",
      "metadata": {},
      "outputs": [
       {
        "data": {
         "image/png": "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",
         "text/plain": [
          "<Figure size 640x480 with 1 Axes>"
         ]
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ],
      "source": [
       "# Diplay rating scores in bar chart\n",
       "import matplotlib.pyplot as plt\n",
       "from operator import countOf\n",
       "\n",
       "rating_scores = []\n",
       "for question in questions:\n",
       "    if 'rating_score' in question: \n",
       "        rating_scores.append(question['rating_score'])\n",
       "\n",
       "bar_labels = []\n",
       "rating_scores_count = []\n",
       "\n",
       "for x in range(11):\n",
       "    bar_labels.append(str(x))\n",
       "    rating_scores_count.append(countOf(rating_scores,str(x)))\n",
       "\n",
       "fig, ax = plt.subplots()\n",
       "ax.bar(bar_labels, rating_scores_count)\n",
       "ax.set_ylabel('Distribution')\n",
       "ax.set_xlabel('Rating score')\n",
       "plt.axvline(x=average_rating, color='tab:red')\n",
       "plt.legend(['Average rating score','Distribution rating score'])\n",
       "plt.show()\n"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "2e4c565e-ca5e-4a7a-9587-7d036228c609",
      "metadata": {},
      "source": [
       "## 5. Generate explanation for average rating score"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "019df54a-1c4d-4096-9508-f4ee356feb08",
      "metadata": {},
      "source": [
       "To explain the average rating score, each rating explanation can be used to create a summary and identiy areas for improvements to further optimize the application."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 14,
      "id": "bfa61bdc-e5dc-4ccf-833f-2c07414d8b9e",
      "metadata": {},
      "outputs": [],
      "source": [
       "# Define prompt to summarize all ratings to explain the given average rating\n",
       "summary_prompt_template = \"\"\"HUMAN:\n",
       "<role>Please act as an impartial summarizer and summarize the following explanations from a LLM as a judge to one single statement</role>\n",
       "<task>Explain the main areas for improvement. Also, write a concise summary of the following explantions from a LLM as a judge to explain the average rating given which the LLM as judge gave. </task>\n",
       "\n",
       "<average_rating>{average_rating}</average_rating>\n",
       "<explanations>{explanations}</explanations>\n",
       "ANSWER:\"\"\"\n",
       "summary_prompt = PromptTemplate.from_template(summary_prompt_template)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 15,
      "id": "fa67becf-81e3-4ae3-aab5-b5dcf5094863",
      "metadata": {},
      "outputs": [],
      "source": [
       "explanation_avg_rating = eval_llm.invoke(summary_prompt.format(average_rating=average_rating, explanations=explanation_rating)).content"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 16,
      "id": "cf44bb82-9c23-49d2-b2fe-c4041d030c6a",
      "metadata": {},
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "Based on the explanations provided, the main areas for improvement seem to be:\n",
         "\n",
         "1. Providing more concise summaries or conclusions at times to reinforce the key points.\n",
         "2. Expanding on certain aspects with additional details, examples, or context where relevant.\n",
         "3. Analyzing complexities like time/space complexity, alternative approaches, or potential limitations in more depth for some technical responses.\n",
         "\n",
         "As for the average rating of 8.6125 given by the LLM judge, the explanations suggest that the assistant's responses were generally of high quality, demonstrating strong understanding, accuracy, relevance, and helpfulness in addressing the given tasks or questions. The judge commended the assistant's creativity, level of detail, clear explanations, and ability to provide well-reasoned and insightful solutions across a diverse range of topics and scenarios. However, there were occasional opportunities for improvement in areas like conciseness, depth of analysis, and considering additional nuances or perspectives, which likely prevented some responses from achieving a perfect 10/10 rating.\n"
        ]
       }
      ],
      "source": [
       "print(explanation_avg_rating)"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "cea3c480-9d28-4d75-9248-abcae16c45c2",
      "metadata": {},
      "source": [
       "## Conclusion"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "a3f5d0d6-4a5a-49fe-8ff6-8d5f6ddc3fea",
      "metadata": {},
      "source": [
       "The lab demonstrates a practical approach for evaluating large language models (LLMs) using the LLM-as-a-Judge technique with Amazon Bedrock. This method addresses the challenges in evaluating LLMs due to their broad capabilities and the limitations of existing benchmarks in measuring human preferences.\n",
       "\n",
       "By leveraging strong LLM judges, such as Claude 3 Sonnet in this notebook, the lab showcases how to assess the performance of LLMs like Claude Instant on the Multi Turn (MT)-Bench, a benchmark designed to measure alignment with human preferences. \n",
       "\n",
       "This approach makes LLM-as-a-judge a scalable and explainable way to approximate human preferences, which are otherwise very costly to obtain. The notebook provides a step-by-step guide on setting up the environment, loading the MT-Bench questions, generating test answers from the LLM under evaluation, leveraging the Bedrock API to assess the answers using the LLM judge, and visualize the results.\n",
       "\n",
       "The successful demonstration of this LLM-as-a-Judge methodology with Amazon Bedrock demonstrates the potential for developers and researchers working on LLM-based applications to adopt this innovative evaluation technique. By understanding the alignment of their models with human preferences, they can make more informed decisions and continue to improve the capabilities of these powerful language models."
      ]
     }
    ],
    "metadata": {
     "availableInstances": [
      {
       "_defaultOrder": 0,
       "_isFastLaunch": true,
       "category": "General purpose",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 4,
       "name": "ml.t3.medium",
       "vcpuNum": 2
      },
      {
       "_defaultOrder": 1,
       "_isFastLaunch": false,
       "category": "General purpose",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 8,
       "name": "ml.t3.large",
       "vcpuNum": 2
      },
      {
       "_defaultOrder": 2,
       "_isFastLaunch": false,
       "category": "General purpose",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 16,
       "name": "ml.t3.xlarge",
       "vcpuNum": 4
      },
      {
       "_defaultOrder": 3,
       "_isFastLaunch": false,
       "category": "General purpose",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 32,
       "name": "ml.t3.2xlarge",
       "vcpuNum": 8
      },
      {
       "_defaultOrder": 4,
       "_isFastLaunch": true,
       "category": "General purpose",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 8,
       "name": "ml.m5.large",
       "vcpuNum": 2
      },
      {
       "_defaultOrder": 5,
       "_isFastLaunch": false,
       "category": "General purpose",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 16,
       "name": "ml.m5.xlarge",
       "vcpuNum": 4
      },
      {
       "_defaultOrder": 6,
       "_isFastLaunch": false,
       "category": "General purpose",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 32,
       "name": "ml.m5.2xlarge",
       "vcpuNum": 8
      },
      {
       "_defaultOrder": 7,
       "_isFastLaunch": false,
       "category": "General purpose",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 64,
       "name": "ml.m5.4xlarge",
       "vcpuNum": 16
      },
      {
       "_defaultOrder": 8,
       "_isFastLaunch": false,
       "category": "General purpose",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 128,
       "name": "ml.m5.8xlarge",
       "vcpuNum": 32
      },
      {
       "_defaultOrder": 9,
       "_isFastLaunch": false,
       "category": "General purpose",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 192,
       "name": "ml.m5.12xlarge",
       "vcpuNum": 48
      },
      {
       "_defaultOrder": 10,
       "_isFastLaunch": false,
       "category": "General purpose",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 256,
       "name": "ml.m5.16xlarge",
       "vcpuNum": 64
      },
      {
       "_defaultOrder": 11,
       "_isFastLaunch": false,
       "category": "General purpose",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 384,
       "name": "ml.m5.24xlarge",
       "vcpuNum": 96
      },
      {
       "_defaultOrder": 12,
       "_isFastLaunch": false,
       "category": "General purpose",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 8,
       "name": "ml.m5d.large",
       "vcpuNum": 2
      },
      {
       "_defaultOrder": 13,
       "_isFastLaunch": false,
       "category": "General purpose",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 16,
       "name": "ml.m5d.xlarge",
       "vcpuNum": 4
      },
      {
       "_defaultOrder": 14,
       "_isFastLaunch": false,
       "category": "General purpose",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 32,
       "name": "ml.m5d.2xlarge",
       "vcpuNum": 8
      },
      {
       "_defaultOrder": 15,
       "_isFastLaunch": false,
       "category": "General purpose",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 64,
       "name": "ml.m5d.4xlarge",
       "vcpuNum": 16
      },
      {
       "_defaultOrder": 16,
       "_isFastLaunch": false,
       "category": "General purpose",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 128,
       "name": "ml.m5d.8xlarge",
       "vcpuNum": 32
      },
      {
       "_defaultOrder": 17,
       "_isFastLaunch": false,
       "category": "General purpose",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 192,
       "name": "ml.m5d.12xlarge",
       "vcpuNum": 48
      },
      {
       "_defaultOrder": 18,
       "_isFastLaunch": false,
       "category": "General purpose",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 256,
       "name": "ml.m5d.16xlarge",
       "vcpuNum": 64
      },
      {
       "_defaultOrder": 19,
       "_isFastLaunch": false,
       "category": "General purpose",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 384,
       "name": "ml.m5d.24xlarge",
       "vcpuNum": 96
      },
      {
       "_defaultOrder": 20,
       "_isFastLaunch": false,
       "category": "General purpose",
       "gpuNum": 0,
       "hideHardwareSpecs": true,
       "memoryGiB": 0,
       "name": "ml.geospatial.interactive",
       "supportedImageNames": [
        "sagemaker-geospatial-v1-0"
       ],
       "vcpuNum": 0
      },
      {
       "_defaultOrder": 21,
       "_isFastLaunch": true,
       "category": "Compute optimized",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 4,
       "name": "ml.c5.large",
       "vcpuNum": 2
      },
      {
       "_defaultOrder": 22,
       "_isFastLaunch": false,
       "category": "Compute optimized",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 8,
       "name": "ml.c5.xlarge",
       "vcpuNum": 4
      },
      {
       "_defaultOrder": 23,
       "_isFastLaunch": false,
       "category": "Compute optimized",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 16,
       "name": "ml.c5.2xlarge",
       "vcpuNum": 8
      },
      {
       "_defaultOrder": 24,
       "_isFastLaunch": false,
       "category": "Compute optimized",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 32,
       "name": "ml.c5.4xlarge",
       "vcpuNum": 16
      },
      {
       "_defaultOrder": 25,
       "_isFastLaunch": false,
       "category": "Compute optimized",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 72,
       "name": "ml.c5.9xlarge",
       "vcpuNum": 36
      },
      {
       "_defaultOrder": 26,
       "_isFastLaunch": false,
       "category": "Compute optimized",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 96,
       "name": "ml.c5.12xlarge",
       "vcpuNum": 48
      },
      {
       "_defaultOrder": 27,
       "_isFastLaunch": false,
       "category": "Compute optimized",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 144,
       "name": "ml.c5.18xlarge",
       "vcpuNum": 72
      },
      {
       "_defaultOrder": 28,
       "_isFastLaunch": false,
       "category": "Compute optimized",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 192,
       "name": "ml.c5.24xlarge",
       "vcpuNum": 96
      },
      {
       "_defaultOrder": 29,
       "_isFastLaunch": true,
       "category": "Accelerated computing",
       "gpuNum": 1,
       "hideHardwareSpecs": false,
       "memoryGiB": 16,
       "name": "ml.g4dn.xlarge",
       "vcpuNum": 4
      },
      {
       "_defaultOrder": 30,
       "_isFastLaunch": false,
       "category": "Accelerated computing",
       "gpuNum": 1,
       "hideHardwareSpecs": false,
       "memoryGiB": 32,
       "name": "ml.g4dn.2xlarge",
       "vcpuNum": 8
      },
      {
       "_defaultOrder": 31,
       "_isFastLaunch": false,
       "category": "Accelerated computing",
       "gpuNum": 1,
       "hideHardwareSpecs": false,
       "memoryGiB": 64,
       "name": "ml.g4dn.4xlarge",
       "vcpuNum": 16
      },
      {
       "_defaultOrder": 32,
       "_isFastLaunch": false,
       "category": "Accelerated computing",
       "gpuNum": 1,
       "hideHardwareSpecs": false,
       "memoryGiB": 128,
       "name": "ml.g4dn.8xlarge",
       "vcpuNum": 32
      },
      {
       "_defaultOrder": 33,
       "_isFastLaunch": false,
       "category": "Accelerated computing",
       "gpuNum": 4,
       "hideHardwareSpecs": false,
       "memoryGiB": 192,
       "name": "ml.g4dn.12xlarge",
       "vcpuNum": 48
      },
      {
       "_defaultOrder": 34,
       "_isFastLaunch": false,
       "category": "Accelerated computing",
       "gpuNum": 1,
       "hideHardwareSpecs": false,
       "memoryGiB": 256,
       "name": "ml.g4dn.16xlarge",
       "vcpuNum": 64
      },
      {
       "_defaultOrder": 35,
       "_isFastLaunch": false,
       "category": "Accelerated computing",
       "gpuNum": 1,
       "hideHardwareSpecs": false,
       "memoryGiB": 61,
       "name": "ml.p3.2xlarge",
       "vcpuNum": 8
      },
      {
       "_defaultOrder": 36,
       "_isFastLaunch": false,
       "category": "Accelerated computing",
       "gpuNum": 4,
       "hideHardwareSpecs": false,
       "memoryGiB": 244,
       "name": "ml.p3.8xlarge",
       "vcpuNum": 32
      },
      {
       "_defaultOrder": 37,
       "_isFastLaunch": false,
       "category": "Accelerated computing",
       "gpuNum": 8,
       "hideHardwareSpecs": false,
       "memoryGiB": 488,
       "name": "ml.p3.16xlarge",
       "vcpuNum": 64
      },
      {
       "_defaultOrder": 38,
       "_isFastLaunch": false,
       "category": "Accelerated computing",
       "gpuNum": 8,
       "hideHardwareSpecs": false,
       "memoryGiB": 768,
       "name": "ml.p3dn.24xlarge",
       "vcpuNum": 96
      },
      {
       "_defaultOrder": 39,
       "_isFastLaunch": false,
       "category": "Memory Optimized",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 16,
       "name": "ml.r5.large",
       "vcpuNum": 2
      },
      {
       "_defaultOrder": 40,
       "_isFastLaunch": false,
       "category": "Memory Optimized",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 32,
       "name": "ml.r5.xlarge",
       "vcpuNum": 4
      },
      {
       "_defaultOrder": 41,
       "_isFastLaunch": false,
       "category": "Memory Optimized",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 64,
       "name": "ml.r5.2xlarge",
       "vcpuNum": 8
      },
      {
       "_defaultOrder": 42,
       "_isFastLaunch": false,
       "category": "Memory Optimized",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 128,
       "name": "ml.r5.4xlarge",
       "vcpuNum": 16
      },
      {
       "_defaultOrder": 43,
       "_isFastLaunch": false,
       "category": "Memory Optimized",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 256,
       "name": "ml.r5.8xlarge",
       "vcpuNum": 32
      },
      {
       "_defaultOrder": 44,
       "_isFastLaunch": false,
       "category": "Memory Optimized",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 384,
       "name": "ml.r5.12xlarge",
       "vcpuNum": 48
      },
      {
       "_defaultOrder": 45,
       "_isFastLaunch": false,
       "category": "Memory Optimized",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 512,
       "name": "ml.r5.16xlarge",
       "vcpuNum": 64
      },
      {
       "_defaultOrder": 46,
       "_isFastLaunch": false,
       "category": "Memory Optimized",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 768,
       "name": "ml.r5.24xlarge",
       "vcpuNum": 96
      },
      {
       "_defaultOrder": 47,
       "_isFastLaunch": false,
       "category": "Accelerated computing",
       "gpuNum": 1,
       "hideHardwareSpecs": false,
       "memoryGiB": 16,
       "name": "ml.g5.xlarge",
       "vcpuNum": 4
      },
      {
       "_defaultOrder": 48,
       "_isFastLaunch": false,
       "category": "Accelerated computing",
       "gpuNum": 1,
       "hideHardwareSpecs": false,
       "memoryGiB": 32,
       "name": "ml.g5.2xlarge",
       "vcpuNum": 8
      },
      {
       "_defaultOrder": 49,
       "_isFastLaunch": false,
       "category": "Accelerated computing",
       "gpuNum": 1,
       "hideHardwareSpecs": false,
       "memoryGiB": 64,
       "name": "ml.g5.4xlarge",
       "vcpuNum": 16
      },
      {
       "_defaultOrder": 50,
       "_isFastLaunch": false,
       "category": "Accelerated computing",
       "gpuNum": 1,
       "hideHardwareSpecs": false,
       "memoryGiB": 128,
       "name": "ml.g5.8xlarge",
       "vcpuNum": 32
      },
      {
       "_defaultOrder": 51,
       "_isFastLaunch": false,
       "category": "Accelerated computing",
       "gpuNum": 1,
       "hideHardwareSpecs": false,
       "memoryGiB": 256,
       "name": "ml.g5.16xlarge",
       "vcpuNum": 64
      },
      {
       "_defaultOrder": 52,
       "_isFastLaunch": false,
       "category": "Accelerated computing",
       "gpuNum": 4,
       "hideHardwareSpecs": false,
       "memoryGiB": 192,
       "name": "ml.g5.12xlarge",
       "vcpuNum": 48
      },
      {
       "_defaultOrder": 53,
       "_isFastLaunch": false,
       "category": "Accelerated computing",
       "gpuNum": 4,
       "hideHardwareSpecs": false,
       "memoryGiB": 384,
       "name": "ml.g5.24xlarge",
       "vcpuNum": 96
      },
      {
       "_defaultOrder": 54,
       "_isFastLaunch": false,
       "category": "Accelerated computing",
       "gpuNum": 8,
       "hideHardwareSpecs": false,
       "memoryGiB": 768,
       "name": "ml.g5.48xlarge",
       "vcpuNum": 192
      },
      {
       "_defaultOrder": 55,
       "_isFastLaunch": false,
       "category": "Accelerated computing",
       "gpuNum": 8,
       "hideHardwareSpecs": false,
       "memoryGiB": 1152,
       "name": "ml.p4d.24xlarge",
       "vcpuNum": 96
      },
      {
       "_defaultOrder": 56,
       "_isFastLaunch": false,
       "category": "Accelerated computing",
       "gpuNum": 8,
       "hideHardwareSpecs": false,
       "memoryGiB": 1152,
       "name": "ml.p4de.24xlarge",
       "vcpuNum": 96
      },
      {
       "_defaultOrder": 57,
       "_isFastLaunch": false,
       "category": "Accelerated computing",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 32,
       "name": "ml.trn1.2xlarge",
       "vcpuNum": 8
      },
      {
       "_defaultOrder": 58,
       "_isFastLaunch": false,
       "category": "Accelerated computing",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 512,
       "name": "ml.trn1.32xlarge",
       "vcpuNum": 128
      },
      {
       "_defaultOrder": 59,
       "_isFastLaunch": false,
       "category": "Accelerated computing",
       "gpuNum": 0,
       "hideHardwareSpecs": false,
       "memoryGiB": 512,
       "name": "ml.trn1n.32xlarge",
       "vcpuNum": 128
      }
     ],
     "instance_type": "ml.t3.medium",
     "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 5
   }
   